{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df204ef",
   "metadata": {},
   "source": [
    "## Dataset Info in MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e573a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_uri = \"s3://dataset/win_assist_dataset/v1.0/mistral_inst_format.json\"\n",
    "dataset_version = \"v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"json\", data_files=train_dataset_uri)[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464aa53",
   "metadata": {},
   "source": [
    "## Load base model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3367ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4fd6c",
   "metadata": {},
   "source": [
    "## LoRA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078190a6",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20186c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_mistral_checkpoint\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"mlflow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131123b",
   "metadata": {},
   "source": [
    "## Run MLflow exp run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eebdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"win_assistant_mistral7b_inst\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"mistral7b_lora_finetune_v2\"):\n",
    "    # Log dataset info\n",
    "    mlflow.log_param(\"train_dataset_uri\", train_dataset_uri)\n",
    "    mlflow.log_param(\"train_dataset_version\", dataset_version)\n",
    "\n",
    "    # Log model + LoRA hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"model_name\": model_name,\n",
    "        \"lora_r\": peft_config.r,\n",
    "        \"lora_alpha\": peft_config.lora_alpha,\n",
    "        \"lora_dropout\": peft_config.lora_dropout,\n",
    "        \"target_modules\": \",\".join(peft_config.target_modules),\n",
    "        \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"fp16\": training_args.fp16\n",
    "    })\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,    \n",
    "        train_dataset=train_dataset,\n",
    "        peft_config=peft_config,\n",
    "        args=training_args\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986c115",
   "metadata": {},
   "source": [
    "## Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run_id = mlflow.last_active_run().info.run_id\n",
    "\n",
    "tokenizer_no_pad = AutoTokenizer.from_pretrained(model_name, add_bos_token=True)\n",
    "\n",
    "with mlflow.start_run(run_id=last_run_id):\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\"model\": trainer.model, \"tokenizer\": tokenizer_no_pad},\n",
    "        name=\"win_assist_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4773e",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e42dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_model = mlflow.pyfunc.load_model(\"runs:/c7af974a12444890acd4d10bcf736935/win_assist_model\").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_query = mlflow_model.predict(\"Open notepad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc06b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "win_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
